{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c83b843",
   "metadata": {},
   "source": [
    "# Animal Faces Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed15be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kaggle datasets download -d andrewmvd/animal-faces\n",
    "# !unzip animal-faces.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287d6b97",
   "metadata": {},
   "source": [
    "## Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ff66f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn # for building the models arch. \n",
    "from torch.optim import Adam # optimizer for training the model\n",
    "import torchvision.transforms as transforms # for the data augmentation and preprocessing\n",
    "from torch.utils.data import Dataset, DataLoader # for creating custom datasets and loading data in batches\n",
    "from sklearn.preprocessing import LabelEncoder # for encoding the labels of the dataset\n",
    "from PIL import Image # for image processing\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device: \", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ddc2cd",
   "metadata": {},
   "source": [
    "## Reading Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6c691d",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e21e4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<StringArray>\n",
      "['cat', 'dog', 'wild']\n",
      "Length: 3, dtype: str\n",
      "                                          image_path label\n",
      "0  data/animal-faces/train/cat/pixabay_cat_000455...   cat\n",
      "1  data/animal-faces/train/cat/pixabay_cat_001993...   cat\n",
      "2  data/animal-faces/train/cat/pixabay_cat_004633...   cat\n",
      "3  data/animal-faces/train/cat/pixabay_cat_002242...   cat\n",
      "4  data/animal-faces/train/cat/pixabay_cat_002524...   cat\n",
      "                                              image_path label\n",
      "16125  data/animal-faces/val/wild/flickr_wild_003335.jpg  wild\n",
      "16126  data/animal-faces/val/wild/flickr_wild_002942.jpg  wild\n",
      "16127  data/animal-faces/val/wild/flickr_wild_000833.jpg  wild\n",
      "16128  data/animal-faces/val/wild/flickr_wild_002956.jpg  wild\n",
      "16129  data/animal-faces/val/wild/flickr_wild_003137.jpg  wild\n"
     ]
    }
   ],
   "source": [
    "image_path = []\n",
    "labels = []\n",
    "\n",
    "# Reading each image and its corresponding label from the dataset\n",
    "for i in os.listdir(\"data/animal-faces\"):\n",
    "    # print(\"\\nProcessing folder: \", i)\n",
    "    for label in os.listdir(f\"data/animal-faces/{i}\"):\n",
    "        # print(\"Label: \", label)\n",
    "        for image in os.listdir(f\"data/animal-faces/{i}/{label}\"):\n",
    "            # print(\"Image: \", image)\n",
    "            image_path.append(f\"data/animal-faces/{i}/{label}/{image}\")\n",
    "            labels.append(label)\n",
    "\n",
    "# Creating dataframe to store the image paths and their corresponding labels\n",
    "df = pd.DataFrame(zip(image_path, labels), columns=[\"image_path\", \"label\"])\n",
    "\n",
    "print(df[\"label\"].unique())\n",
    "print(df.head())\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c533b4ad",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120d86ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size:  11291\n",
      "Test set size:  2419\n",
      "Validation set size:  2420\n"
     ]
    }
   ],
   "source": [
    "train = df.sample(frac=0.7) # 70% of the data for training\n",
    "test = df.drop(train.index) # remaining 30% for testing\n",
    "val = test.sample(frac=0.5) # 15% of the data of test for validation\n",
    "test = test.drop(val.index) # Remaining 15% for testing\n",
    "\n",
    "print(\"Train set size: \", len(train))\n",
    "print(\"Test set size: \", len(test))\n",
    "print(\"Validation set size: \", len(val))\n",
    "\n",
    "# Label encoding the labels of the dataset\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(df[\"labels\"]) # fitting the label encoder on the labels of the dataset\n",
    "\n",
    "# Makes all the images have the same properties (size, normalization, etc.) before feeding them into the model.\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128,128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.ConvertImageDtype(torch.float32)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5e440e",
   "metadata": {},
   "source": [
    "## Custom Image Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dd240f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnimalFaceDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.labels = torch.tensor(label_encoder.transform(df[\"labels\"].device())) # encoding the labels of the dataset from string to integer\n",
    "        \n",
    "    def __len(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.iloc[idx,0] # getting the image path from the dataframe\n",
    "        label = self.labels[idx] # getting the label from the encoded labels (integers)\n",
    "        \n",
    "        image = Image.open(img_path).convert(\"RGB\") # opening the image and converting it to RGB\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image).to(device) # Moving to device\n",
    "            \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec3b681",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "animal-faces",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
